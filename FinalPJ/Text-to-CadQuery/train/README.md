# Training Scripts

This folder contains scripts to finetune six open-source language models for the task of generating CadQuery code from natural language descriptions.

## Models

- `train_codegpt_small_py.py` â€” Finetunes CodeGPT-small-py
- `train_gpt2_medium.py` â€” Finetunes GPT-2 Medium
- `train_gpt2_large.py` â€” Finetunes GPT-2 Large
- `train_gemma-1B.py` â€” Finetunes Gemma3 1B
- `train_qwen-3B.py` â€” Finetunes Qwen2.5 3B
- `train_mistral-7B_lora.py` â€” Finetunes Mistral-7B using LoRA

All models are trained using prompt-completion JSONL data in supervised fine-tuning (SFT) mode.

## Dataset

The dataset is split into three parts:

- `data_train.jsonl` â€” 90% for training  
- `data_val.jsonl` â€” 5% for validation  
- `data_test.jsonl` â€” 5% for held-out evaluation  

It is publicly available at:  
ðŸ‘‰ [https://huggingface.co/ricemonster/NeurIPS11092/tree/main/data](https://huggingface.co/ricemonster/NeurIPS11092/tree/main/data)